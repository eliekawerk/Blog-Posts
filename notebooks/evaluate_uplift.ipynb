{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b02b64ee-ab8b-45d4-8d40-d6aa7ab4efbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaulating Uplift Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac7f82e-17bf-4824-86dd-0b361a9e1a5f",
   "metadata": {},
   "source": [
    "One of the most widespread applications of causal inference in the industry is **uplift modeling**, a.k.a. the estimation of Conditional Average Treatment Effects.\n",
    "\n",
    "When estimating the causal effect of a **treatment** (a drug, ad, product, ...) on an **outcome** of interest (a disease, firm revenue, customer satisfaction, ...), we are often not only interested in understanding whether the treatment works on average, but we would like to know for which **subjects** (patients, users, customers, ...) it works better or worse. \n",
    "\n",
    "The estimation of heterogenous incremental effects, or uplift, is an essential intermediate step in order to improve **targeting** of the policy of interest. For example, we might want to warn certain people that they are more likely to experience side effects from a drug or show an advertisement only to a specific set of customers.\n",
    "\n",
    "While there exist many methods to model uplift, it is not always clear which one to use in a specific application. Crucially, because of the **fundamental problem of causal inference**, the objective of interest, the uplift, is never observed, and therefore we cannot validate our estimators as we would do with a machine learning prediction algorithm. We cannot set aside a validation set and pick the best-performing model since we have **no ground truth**, not even in the validation set and not even if we ran a randomized experiment.\n",
    "\n",
    "What can we do then? In this article, I try to cover the most popular methods used to **evaluate uplift models**. If you are not familiar with uplift models, I suggest reading [my introductory article](https://towardsdatascience.com/8a9c1e340832) first.\n",
    "\n",
    "Enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a748a381-48ed-4ad4-8728-41311371caae",
   "metadata": {},
   "source": [
    "## Uplift and Promotional Emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b1d9d4-e9c1-4149-8a0b-49c5b4012ba5",
   "metadata": {},
   "source": [
    "Imagine we were a product company interested in improving our **email marketing campaing**. Historically, we mostly sent emails to new customers. However, now we would like to adopt a data-drive approach and terget customers for whom the email has the highest positive impact on revenue. This impact is also called **uplift** or **incrementality**.\n",
    "\n",
    "Let's have a look at the data we have at our disposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22cf8401-6ffa-4f22-b85e-65a9681e8c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d166a29-c389-40ec-b6d2-028bd9c3a7be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.utils import *\n",
    "from src.dgp import dgp_promotional_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4579de5d-20f1-4696-b01d-e1db675118c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new</th>\n",
       "      <th>age</th>\n",
       "      <th>sales_old</th>\n",
       "      <th>mail</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>56.26</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50.96</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>23.24</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>36.29</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new    age  sales_old  mail  sales\n",
       "0    0  56.26       0.29     1   0.36\n",
       "1    1  50.96       0.54     0   0.56\n",
       "2    1  33.33       0.32     0   0.36\n",
       "3    0  23.24       0.15     1   0.10\n",
       "4    0  36.29       0.18     1   0.22"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgp = dgp_promotional_email(n=300)\n",
    "df = dgp.generate_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8fc33b-3769-46eb-afdb-9708c2ed648a",
   "metadata": {},
   "source": [
    "We have information on 500 customers, for whom we observe whether they are `new` customers, their `age`, the sales they generated before the email campaign (`sales_old`), whether they were sent the `mail`, and the `sales` after the email campaign.\n",
    "\n",
    "The **outcome** of interest is `sales`, which we denote with the letter *Y*. The **treatment** or policy that we would like to improve is the `mail` campaign, which we denote with the letter *W*. We call all the remaining variables **confounders** or control variables and we denote them with *X*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "031fee37-6b4a-4750-9c2a-1d0d0aeacafe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y = 'sales'\n",
    "W = 'mail'\n",
    "X = ['age', 'sales_old', 'new']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26fbfc5-df09-4f2e-944a-08aec20dd83b",
   "metadata": {},
   "source": [
    "The Dyrected Acyclic Graph (DAG) behind the data generate process can be represented as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27512c9-c75a-4627-baa1-a47379102cba",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart TD\n",
    "classDef included fill:#DCDCDC,stroke:#000000,stroke-width:3px;\n",
    "\n",
    "W((mail))\n",
    "Y((sales))\n",
    "X1((new))\n",
    "X2((age))\n",
    "X3((sales old))\n",
    "\n",
    "W --> Y\n",
    "X1 --> W\n",
    "X1 --> Y\n",
    "X2 --> Y\n",
    "X3 --> Y\n",
    "\n",
    "class W,Y,X1,X2,X3 included;\n",
    "\n",
    "linkStyle 0 stroke:#2db88b,stroke-width:6px;\n",
    "linkStyle 1,2,3,4 stroke:#003f5c,stroke-width:6px;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557041e1-58c4-4f5a-bac4-3423a42e4e3d",
   "metadata": {},
   "source": [
    "The objective of uplift modeling is to recover the **Individual Treatment Effects (ITE)** $\\tau_i$, i.e. the incremental effect on `sales` of sending the promotional `mail`. We can express the ITE as the difference between two hypothetical quantities: the potential outcome of the customer if they had received the email, $Y_i^{(1)}$, minus the potential outcome of the customer if they had *not* received the email, $Y_i^{(0)}$.\n",
    "$$\n",
    "\\tau_i = Y_i^{(1)} - Y_i^{(0)}\n",
    "$$\n",
    "\n",
    "Note that for each customer, we only observe one of the two realized outcomes, depending on whether they actually received the `mail` or not. Therefore, the ITE are inherently unobservable. What can be estimated instead is the **Conditional Average Treatment Effect (CATE)** i.e., the expected individual treatment effect $\\tau_i$, conditional on covariates *X*.\n",
    "$$\n",
    "\\tau(x) = \\mathbb{E} \\Big[ \\ \\tau_i \\ \\Big| \\ X_i = x \\Big]\n",
    "$$\n",
    "\n",
    "In order to be able to recover the CATE, we need to make three assumptions.\n",
    "\n",
    "1. **Unconfoundedness**: $Y^{(0)}, Y^{(1)} \\perp W \\ | \\ X$\n",
    "\n",
    "2. **Overlap**: $0 < e(X) < 1$\n",
    "\n",
    "3. **Consistency**: $Y = W * Y^{(1)} + (1-W) * Y^{(0)}$\n",
    "\n",
    "Where $e(X)$ is the **propensity score** i.e., the expected probability of being treated, conditional on covariates *X*.\n",
    "$$\n",
    "e(x) = \\mathbb{E} \\Big[ \\ W_i \\ \\Big| \\ X_i = x \\Big]\n",
    "$$\n",
    "\n",
    "\n",
    "In what follows, we will use machine learning methods to estimate the CATE $\\tau(x)$, the propensity scores $e(x)$, and the conditional expectation function of the outcome, $\\mu(x)$\n",
    "$$\n",
    "\\mu(x) = \\mathbb{E} \\Big[ \\ y_i \\ \\Big| \\ X_i = x \\Big]\n",
    "$$\n",
    "\n",
    "We use [Random Forest Regression](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) algorithms to model the CATE and the outcome CEF, while we use [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to model the propensity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "583ddc30-6747-42f5-8519-fc7a8d86dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "model_tau = RandomForestRegressor(max_depth=2)\n",
    "model_y = RandomForestRegressor(max_depth=2)\n",
    "model_e = LogisticRegressionCV()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbca655c-19fd-4764-9306-f83c4d747122",
   "metadata": {},
   "source": [
    "In this article, we do not fine tune the different regression functions, but it is strongly recommended to improve the accuracy of uplift models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b45196-7551-4562-a8b6-b3f7c1d0a905",
   "metadata": {},
   "source": [
    "## Uplift Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d8ffe-523b-4b6c-ae71-30c6ace00ade",
   "metadata": {},
   "source": [
    "There exist **many methods** to model uplift or, in other words, to estimate Conditional Average Treatment Effects. Since the objective of this article is not to compare uplift models but methods to evaluate uplift models, we will not explain the models in detail. For a gentle introduction, you can check [my article on meta learners](https://medium.com/towards-data-science/understanding-meta-learners-8a9c1e340832).\n",
    "\n",
    "The learners that we will consider are the following:\n",
    "\n",
    "- S-learner or single-learner, introduced by [Kunzel, Sekhon, Bickel, Yu (2017)](https://arxiv.org/abs/1706.03461)\n",
    "\n",
    "- T-learner or two-learner, introduced by [Kunzel, Sekhon, Bickel, Yu (2017)](https://arxiv.org/abs/1706.03461)\n",
    "\n",
    "- X-learner or cross-learner, introduced by [Kunzel, Sekhon, Bickel, Yu (2017)](https://arxiv.org/abs/1706.03461)\n",
    "\n",
    "- R-learner (from [Robinson (1988)](https://www.jstor.org/stable/1912705)) introduced by [Nie, Wager (2017)](https://arxiv.org/abs/1712.04912)\n",
    "\n",
    "- DR-learner or doubly-robust-learner, introduced by [Kennedy (2022)](https://arxiv.org/abs/2004.14497)\n",
    "\n",
    "\n",
    "We import all the model from Microsoft's [econml](https://econml.azurewebsites.net/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8404052-bca4-48e7-8414-3b5e33d7ae5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from econml.metalearners import SLearner, TLearner, XLearner\n",
    "from econml.dml import NonParamDML\n",
    "from econml.dr import DRLearner\n",
    "\n",
    "S_learner = SLearner(overall_model=model_y).fit(df[Y], df[W], X=df[X])\n",
    "T_learner = TLearner(models=clone(model_y)).fit(df[Y], df[W], X=df[X])\n",
    "X_learner = XLearner(models=model_y, propensity_model=model_e, cate_models=model_tau).fit(df[Y], df[W], X=df[X])\n",
    "R_learner = NonParamDML(model_y=model_y, model_t=model_e, model_final=model_tau, discrete_treatment=True\n",
    "                       ).fit(df[Y], df[W], X=df[X])\n",
    "DR_learner = DRLearner(model_regression=model_y, model_propensity=model_e, model_final=model_tau\n",
    "                      ).fit(df[Y], df[W], X=df[X])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d334ebd-bb27-40d6-9459-897c3226d859",
   "metadata": {},
   "source": [
    "## Oracle Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8369eb-b715-4a6a-aabe-3c245b2110bc",
   "metadata": {},
   "source": [
    "The main problem of evaluating uplift models is that, even when running an experiment and even when setting aside a validation dataset, we do **not observe** our metric of interest: the Individual Treatment Effects. Can we still do something to evaluate our estimators?\n",
    "\n",
    "The answer is yes, but before giving more details, let's first understand what we would do if we **could observe** the Individual Treatment Effects $\\tau_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "597320c8-8e00-465e-9960-5b81ebadaaf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names = ['SL', 'TL', 'XL', 'RL', 'DRL']\n",
    "learners = [S_learner, T_learner, X_learner, R_learner, DR_learner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4999a026-dbae-4de0-9e09-1f39ece16e06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_methods(learners, names, loss, title=None, subtitle='lower is better'):\n",
    "    results = pd.DataFrame({\n",
    "        'learner': names,\n",
    "        'loss': [loss(learner) for learner in learners]\n",
    "    })\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "    sns.barplot(data=results, x=\"learner\", y='loss').set(ylabel='')\n",
    "    plt.suptitle(title, y=1.02)\n",
    "    plt.title(subtitle, fontsize=12, fontweight=None, y=0.94)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a9b3f7-1283-443d-8cb5-e3a082a065ef",
   "metadata": {},
   "source": [
    "### Oracle MSE Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7dc846-795d-4e6e-b48f-ad9e09c36b43",
   "metadata": {},
   "source": [
    "If we could observe the individual treatment effects (but we don't), we could try to measure how far our estimates $\\hat{\\tau}(X_i)$ are with respect to the true value $\\tau_i$. This is what we normally do in machine learning when we want to evaluate a prediction method. There exist plenty of loss functions, so let's concentrate on the most popular one: the **Mean Squared Error (MSE) loss**.\n",
    "\n",
    "$$\n",
    "\\mathcal{L} _ {oracle-MSE}(\\hat{\\tau}) = \\frac{1}{n} \\sum _ {i=1}^{n} \\left( \\hat{\\tau}(X_i) - \\tau(X_i) \\right)^2\n",
    "$$\n",
    "\n",
    "Let's compute it across our uplift models. We compute it on a validation dataset with 10.000 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9583e38d-f840-4cfb-8ca9-4e8c08320963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_oracle_mse(learner):\n",
    "    data = generate_data(N=10_000, seed=123, true_te=True)\n",
    "    tau = learner.effect(data[X])\n",
    "    return np.mean((tau - data['effect'])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1017f084-a1ad-4545-b222-a08d332be64c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompare_methods\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearners\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_oracle_mse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOracle MSE Loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m, in \u001b[0;36mcompare_methods\u001b[0;34m(learners, names, loss, title, subtitle)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare_methods\u001b[39m(learners, names, loss, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower is better\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      2\u001b[0m     results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearner\u001b[39m\u001b[38;5;124m'\u001b[39m: names,\n\u001b[0;32m----> 4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43m[\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlearners\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m     })\n\u001b[1;32m      6\u001b[0m     fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      7\u001b[0m     sns\u001b[38;5;241m.\u001b[39mbarplot(data\u001b[38;5;241m=\u001b[39mresults, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearner\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mset(ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare_methods\u001b[39m(learners, names, loss, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, subtitle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower is better\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      2\u001b[0m     results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearner\u001b[39m\u001b[38;5;124m'\u001b[39m: names,\n\u001b[0;32m----> 4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m learner \u001b[38;5;129;01min\u001b[39;00m learners]\n\u001b[1;32m      5\u001b[0m     })\n\u001b[1;32m      6\u001b[0m     fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      7\u001b[0m     sns\u001b[38;5;241m.\u001b[39mbarplot(data\u001b[38;5;241m=\u001b[39mresults, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearner\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mset(ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m, in \u001b[0;36mloss_oracle_mse\u001b[0;34m(learner)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_oracle_mse\u001b[39m(learner):\n\u001b[0;32m----> 2\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_data\u001b[49m(N\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10_000\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m, true_te\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m     tau \u001b[38;5;241m=\u001b[39m learner\u001b[38;5;241m.\u001b[39meffect(data[X])\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean((tau \u001b[38;5;241m-\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meffect\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_data' is not defined"
     ]
    }
   ],
   "source": [
    "compare_methods(learners, names, loss_oracle_mse, title='Oracle MSE Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653a2e44-027e-4925-8747-ebf8d702e5c7",
   "metadata": {},
   "source": [
    "In this case, we see that the T-learner clearly performs worst, while X-, D- and DR-learners perform best, with the R-learner slightly winning the race.\n",
    "\n",
    "However, this might not be the best loss function. In fact, uplift modeling is just an intermediate step towards our ultimate goal: improving revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a252fd-241d-46fd-a949-5490f3b6842f",
   "metadata": {},
   "source": [
    "### Oracle Policy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39b2c02-e18d-47c7-918e-e246ee2066b0",
   "metadata": {},
   "source": [
    "Since our ultimate goal is to improve revenue, we could evaluate estimators by how much they increase revenue, given a certain policy function. Suppose, for example, that we had a $0.01\\$$ cost of sending an email. Then, our policy would be to treat each costumer that has a predicted Conditional Average Treatment Effect above $0.01\\$$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdedc18d-0bee-4721-8e29-23e459119101",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8e734c-7789-410e-aafb-eeab9d4459dd",
   "metadata": {},
   "source": [
    "How much would our revenue actually increase?\n",
    "\n",
    "$$\n",
    "\\mathcal{L} _ {oracle-POLICY}(\\hat{\\tau}) = \\frac{1}{n} \\sum _ {i=1}^{n} \\Big( \\hat{\\tau}(X_i) - \\tau(X_i) \\Big)^2\n",
    "$$\n",
    "\n",
    "Again, this is an \"oracle\" loss function that **cannot be computed** in reality since we do not observe the individual treatment effects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b34fc7-0cc1-4d1d-9a5c-2b568b9b9bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_oracle_policy(learner):\n",
    "    data = generate_data(N=10_000, seed=123, true_te=True)\n",
    "    tau_hat = learner.effect(data[X])\n",
    "    return np.sum(data['effect'] * (tau_hat>c) - c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c830407e-2bbd-46ce-817e-c783c96cb222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare_methods(learners, names, loss_oracle_policy, title='Oracle Policy Loss', subtitle='higher is better')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a92175-dca7-482e-8507-3fc7f02143ef",
   "metadata": {},
   "source": [
    "In this case, the S-learner is clearly the worst performer, leading to an aggregate loss (i.e. we would have been better off not sending any email). On the other hand, X-, R- and DR- learners all lead to aggregate gains, with no clear winner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29ad403-c652-4b0f-86cc-51099e168bb0",
   "metadata": {},
   "source": [
    "## Practical Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45499d71-0802-457d-8b11-4f34c124af51",
   "metadata": {},
   "source": [
    "In the previous section, we have seen two examples of loss functions that we would like to compute if we could observe the Individual Treatment Effects $\\tau_i$. However, in practice, even with a randomized experiment and even with a validation set, we do not observe the ITE,our object of interest. We will now cover some measures that try to evaluate uplift models, given this practical constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4d92c9-97b3-4fa3-bfc7-4aeebd63870a",
   "metadata": {},
   "source": [
    "### Distribution Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b632ae85-2c15-4930-acb3-9a535db0f73a",
   "metadata": {},
   "source": [
    "A different approach is to ask: how well are we able to match the distribution of potential outcomes? \n",
    "\n",
    "$$\n",
    "dist \\ \\Big( \\ \\{Y_i | W_i=0 \\} \\ , \\ \\{Y_i - \\hat{\\tau}(X_i)| W_i=1 \\} \\ \\Big)\n",
    "$$\n",
    "\n",
    "or \n",
    "\n",
    "$$\n",
    "dist \\ \\Big( \\ \\{Y_i + \\hat{\\tau}(X_i)| W_i=0 \\} \\ , \\ \\{Y_i | W_i=1 \\} \\ \\Big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59a7d0-59e4-4b55-be65-5a9e0abf8622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_dist(learner):\n",
    "    data = generate_data(N=10_000, seed=123)\n",
    "    tau = learner.effect(data[X])\n",
    "    y0 = data.loc[data.mail==1, 'sales'] - tau[data.mail==1]\n",
    "    return sp.stats.energy_distance(df.loc[df.mail==0, 'sales'], y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc4302-1091-4572-aa66-a6ade0881295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare_methods(learners, names, loss_dist, 'Distribution Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9666adba-b5d7-43c6-ac0b-8d31ea14eb66",
   "metadata": {},
   "source": [
    "### Above-below Median Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534f65a2-dc9e-445b-918d-8be3ba94ccf9",
   "metadata": {},
   "source": [
    "The above-below median loss tries to answer the question: is our uplift model detecting *any* heterogeneity? In particular, if we take the validation set and we split the sample into above-median and below median predicted uplift $\\hat{\\tau}(x)$, how big is the actual difference in average effect, estimated with a difference-in-means estimator? We would expect better estimators to better split the sample into high-effects and low-effects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c011cea-cba7-44da-a2f1-29dd5d8769cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols \n",
    "\n",
    "def loss_ab(learner):\n",
    "    data = generate_data(N=10_000, seed=123)\n",
    "    tau = learner.effect(data[X]) + np.random.normal(0, 1e-8, len(data))\n",
    "    data['above_median'] = tau >= np.median(tau)\n",
    "    param = ols('sales ~ mail * above_median', data=data).fit().params[-1]\n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f42a5c-4882-411a-be55-139c1c954264",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare_methods(learners, names, loss_ab, title='Above-below Median Difference', subtitle='higher is better')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df916a-e1fd-4c75-86cb-2fc8d026ab18",
   "metadata": {},
   "source": [
    "It's important to note that the difference-in-means estimators in the two groups (above- and below- median $\\hat{\\tau}(x)$) are **not guaranteed to be unbiased**, even if the data came from a randomized experiment. In fact, we have split the two groups on a variable, $\\hat{\\tau}(x)$, that is highly endogenous. Therefore, the method should be used with a grain of salt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa57206-b558-4b55-8fa3-6de113207b5f",
   "metadata": {},
   "source": [
    "### Uplift Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f63f7f-f1ba-4d5d-b038-871432113e7b",
   "metadata": {},
   "source": [
    "An extension of the above-below median test is the **uplift curve**. The idea is simple: instead of splitting the sample into two goups based on the median (0.5 quantile), why not splitting the data into more groups (more quantiles)?\n",
    "\n",
    "For each group, we compute the difference-in-means estimate and we plot its cumulative sum agains the corresponding quantile. The result is called **uplift curve**. The interpretation is simple: the higher the curve, the better we are able to separate high- from low-effect observations. However, also the same **disclaimer** applies: the difference-in-means estimates are not unbiased, therefore have to be used with a grain of salt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0feb17b-157d-472e-b057-1f43b2e7e1ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_uplift_curve(df):\n",
    "    Q = 20\n",
    "    df_q = pd.DataFrame()\n",
    "    data = generate_data(N=10_000, seed=123)\n",
    "    ate = np.mean(data[Y][data[W]==1]) - np.mean(data[Y][data[W]==0])\n",
    "    for learner, name in zip(learners, names):\n",
    "        data['tau_hat'] = learner.effect(data[X])\n",
    "        data['q'] = pd.qcut(-data.tau_hat + np.random.normal(0, 1e-8, len(data)), q=Q, labels=False)\n",
    "        for q in range(Q):\n",
    "            temp = data[data.q <= q]\n",
    "            uplift = (np.mean(temp[Y][temp[W]==1]) - np.mean(temp[Y][temp[W]==0])) * q / (Q-1)\n",
    "            df_q = pd.concat([df_q, pd.DataFrame({'q': [q], 'uplift': [uplift], 'learner': [name]})])\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    sns.lineplot(x=range(Q), y=ate*range(Q)/(Q-1), color='k', ls='--', lw=3)\n",
    "    sns.lineplot(x='q', y='uplift', hue='learner', data=df_q);\n",
    "    plt.suptitle('Uplift Curve', y=1.02, fontsize=28, fontweight='bold')\n",
    "    plt.title('higher is better', fontsize=14, fontweight=None, y=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b3495-82db-43df-b058-6dcc17225756",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_uplift_curve(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c4d9d7-b5c6-45aa-b000-406fbd7c1eb2",
   "metadata": {},
   "source": [
    "While probably not the best method to *evaluate* uplift models, the uplift curve is very important in *understanding* and *implementing* them. In fact, for each models, it tells us that is the expected average treatment effect (y-axis) as we increase the share of treated population (x-axis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ebb17d-a466-4e71-b7c1-dfb06bf1cb04",
   "metadata": {},
   "source": [
    "### Nearest Neighbor Match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e85bec-947f-436f-91c1-955c8246a0f3",
   "metadata": {},
   "source": [
    "The last methods we analyzed aggregated data in order to understand whether the methods work on larger groups. The nearest neighbor match tries instead to understand how well an uplift model predicts individual treatment effects. However, since the ITEs are not observable, it tries to build a proxy by matching treated and control observations on observable characteristics $x$.\n",
    "\n",
    "For example, if we take all treated observations ($i: W_i=1$), and we find the nearest neighbor in the control group ($NN_0(X_i)$), the corresponding MSE loss function is\n",
    "$$\n",
    "\\mathcal{L} _ {NN}(\\hat{\\tau}) = \\frac{1}{n} \\sum _ {i: W_i=1} \\Big( \\hat{\\tau}(X_i) - (Y_i - NN_0(X_i)) \\Big)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d3cf2-afc1-4ff6-b216-31a2f0839c80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "def loss_nn(learner):\n",
    "    data = generate_data(N=10_000, seed=123)\n",
    "    tau_hat = learner.effect(data[X])\n",
    "    nn0 = KDTree(data.loc[data[W]==0, X].values)\n",
    "    control_index = nn0.query(data.loc[data[W]==1, X], k=1)[-1]\n",
    "    tau_nn = data.loc[data[W]==1, Y].values - data.iloc[control_index, :][Y].values\n",
    "    return np.mean((tau_hat[data[W]==1] - tau_nn)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bf93bc-4fce-452c-89ad-f8b4615ac927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare_methods(learners, names, loss_nn, title='Nearest Neighbor Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf7dc0-2d27-41ac-83e8-89de98c4a84c",
   "metadata": {},
   "source": [
    "### IPW Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd01ff-ccda-4a8b-93b2-20ea720427ff",
   "metadata": {},
   "source": [
    "The Inverse Probability Weighting (IPW) loss function was first proposed by [Gutierrez, Gerardy (2017)](https://proceedings.mlr.press/v67/gutierrez17a/gutierrez17a.pdf) and the first of three metrics that we are going to see that uses a **pseudo-outcome** $Y^*$ to evaluate the estimator. As we have seen in the brief introduction to the R- and DR- learner, pseudo-outcomes are variables whose expected value is the Conditional Average Treatment Effect. The pseudo-outcome corresponding to the IPW loss is\n",
    "\n",
    "$$\n",
    "\\mathcal{L} _ {IPW} = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\hat{\\tau}(X_i) - Y_i \\ \\frac{W_i - \\hat{e}(X_i)}{\\hat{e}(X_i)(1 - \\hat{e}(X_i))} \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba20f329-a881-4e53-a88e-305f78a099b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_ipw(learner):\n",
    "    data = generate_data(N=10_000, seed=123)\n",
    "    tau_hat = learner.effect(data[X])\n",
    "    e_hat = clone(model_e).fit(data[X], data[W]).predict_proba(data[X])[:,1]\n",
    "    tau_gg = data[Y] * (data[W] - e_hat) / (e_hat * (1 - e_hat))\n",
    "    return np.mean((tau_hat - tau_gg)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afad1bb8-6f91-485c-a044-60323f5ee993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compare_methods(learners, names, loss_ipw, title='IPW Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1847010a-d754-47f3-92f3-0c83a2d02f30",
   "metadata": {},
   "source": [
    "### R Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e068043b-f6db-4f78-85af-020aa0661ae4",
   "metadata": {},
   "source": [
    "The R-loss was introduced together with the R-learner by [Nie, Wager (2017)](https://arxiv.org/abs/1712.04912), and it is essentially the **objective function** of the R-learner.\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{R} = \\frac{1}{n} \\sum _ {i=1}^{n} \\left( \\hat{\\tau}(X_i) -  \\frac{Y_i - \\hat{\\mu}_W(X_i)}{W_i - \\hat{e}(X_i)} \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306ca4a0-7582-419b-b4f8-0645a0194232",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_r(learner):\n",
    "    data = generate_data(N=10_000, seed=123)\n",
    "    tau_hat = learner.effect(data[X])\n",
    "    y_hat = clone(model_y).fit(df[X + [W]], df[Y]).predict(data[X + [W]])\n",
    "    e_hat = clone(model_e).fit(df[X], df[W]).predict_proba(data[X])[:,1]\n",
    "    tau_nw = (data[Y] - y_hat) / (data[W] - e_hat)\n",
    "    return np.mean((tau_hat - tau_nw)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dead700-3229-4508-b03d-64d4b4b5e177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = compare_methods(learners, names, loss_r, title='R Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ee9fed-c3c9-4e32-bf1e-70c9a8a4b762",
   "metadata": {},
   "source": [
    "Unsurprisingly, the R-loss tends to favor its corresponding learner, the R-learner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be227d-19e8-45d9-888f-efcc49e40ae0",
   "metadata": {},
   "source": [
    "### DR Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd0530-9e39-4d13-bd41-8b58f559cf03",
   "metadata": {},
   "source": [
    "Similarly to the R-loss, the DR-loss is the **objective function** of the DR-learner and it was first introduced by [Saito, Yasui (2020)](https://arxiv.org/abs/1909.05299).\n",
    "\n",
    "$$\n",
    "\\mathcal{L} _ {DR} = \\frac{1}{n} \\sum _ {i=1}^{n} \\left( \\hat{\\tau}(X_i) - \\hat{\\mu}_1(X_i) + \\hat{\\mu}_0(X_i) - (Y_i - \\hat{\\mu}_W(X_i)) \\ \\frac{W_i - \\hat{e}(X_i)}{\\hat{e}(X_i)(1 - \\hat{e}(X_i))} \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8293269-6b97-49af-8a88-d18dcaeec8c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_dr(learner):\n",
    "    data = generate_data(N=10_000, seed=123)\n",
    "    tau_hat = learner.effect(data[X])\n",
    "    y_hat = clone(model_y).fit(df[X + [W]], df[Y]).predict(data[X + [W]])\n",
    "    mu1 = clone(model_y).fit(df[X + [W]], df[Y]).predict(data[X + [W]].assign(mail=1))\n",
    "    mu0 = clone(model_y).fit(df[X + [W]], df[Y]).predict(data[X + [W]].assign(mail=1))\n",
    "    e_hat = clone(model_e).fit(df[X], df[W]).predict_proba(data[X])[:,1]\n",
    "    tau_nw = mu1 - mu0 + (data[Y] - y_hat) * (data[W] - e_hat) / (e_hat * (1 - e_hat))\n",
    "    return np.mean((tau_hat - tau_nw)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf501a12-0ccf-4cb1-8ba9-2de8f6949fd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = compare_methods(learners, names, loss_dr, title='DR Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e160d9c4-a86c-4964-9e66-45db783a0c71",
   "metadata": {},
   "source": [
    "As for the R-loss, the DR-loss tends to favor its corresponding learner, the DR-learner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08ccd1c-3c47-4256-b917-723d3dcaa356",
   "metadata": {},
   "source": [
    "### Empirical Policy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ae519-119f-4dfe-a5eb-cca8b58f48f5",
   "metadata": {},
   "source": [
    "The last loss function that we are going to analyze is different from all the others we have seen so far since it focuses not on how well we are able to estimate the treatment effects, but rather on how well would the corresponding **optimal treatment policy** performs. In particular, [Hitsch, Misra, Zhang (2023)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3111957) propose the following loss function:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} _ {TEP} = \\frac{1}{n} \\sum _ {i=1}^{n} \\left( W_i \\cdot d(X_i) \\cdot \\frac{Y_i - c}{\\hat{e}(X_i)} + (1-W_i) \\cdot (1-d(X_i)) \\cdot \\frac{Y_i}{1-\\hat{e}(X_i)} \\right)\n",
    "$$\n",
    "\n",
    "where $c$ is the treatment cost and $d_i$ is the optimal treatment policy given the estimated CATE $\\hat{\\tau}(X_i)$. In our case, we assume an individual treatment cost of $c=0.01\\$$, so that the optimal policy is to treat every customer with an estimated CATE larger than 0.01, $d(X_i) = (\\hat{\\tau}(X_i) > 0.01)$.\n",
    "\n",
    "The terms $W_i \\cdot d(X_i)$ and $(1-W_i) \\cdot (1-d(X_i))$ imply that we use for the calculation only individuals for whom the actual treatment *W* corresponds with the optimal one, *d(X)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe039f5-ee0c-4514-9347-742f99981d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_policy(learner):\n",
    "    data = generate_data(N=10_000, seed=123)\n",
    "    tau_hat = learner.effect(data[X])\n",
    "    e_hat = clone(model_e).fit(data[X], data[W]).predict_proba(data[X])[:,1]\n",
    "    d = tau_hat > c\n",
    "    return np.sum((d * data[W] * (data[Y]-c)/ e_hat + (1-d) * (1-data[W]) * data[Y] / (1-e_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f2184-f671-47cf-90f0-9158ed94d5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = compare_methods(learners, names, loss_policy, title='Empirical Policy Loss', subtitle='higher is better')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f2680a-7aa4-42bd-8a70-1618c507b77b",
   "metadata": {},
   "source": [
    "## Meta Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7cd3de-569c-4471-9b43-471bff2751f1",
   "metadata": {},
   "source": [
    "In this article we have introduced a wide variety of methods to evaluate uplift models, a.k.a. Conditional Average Treatment Effect estimators. We have also tested in our simulated dataset, which is a very special and limited example. How do these metrics **perform** in general? \n",
    "\n",
    "[Schuler, Baiocchi, Tibshirani, Shah (2018)](https://arxiv.org/abs/1804.05146) compares the S-loss, T-loss, R-loss, on simulated data, for the corresponding estimators. They find that the R-loss \"*is the validation set metric that, when optimized, most consistently leads to the selection of a high-performing model*\".\n",
    "\n",
    "[Curth, van der Schaar (2023)](https://arxiv.org/abs/2302.02923) studies a broader array of learners from a **theoretical perspective**. They find that \"*no existing selection criterion is globally best across all experimental conditions we consider*\". However, they notice that S- and T-learners tend to perform better when the conditional expectation functions $\\mu(X)$ are easier to predict than the CATE $\\tau(X)$, while the R- and DR-learners perform better in the opposite scenario. The X-learner performs best when both functions are equally complex. The **intuition** is that the S- and T- learner focus of modeling $y$, while the R- and DR- learner focus on modeling $\\tau$.\n",
    "\n",
    "[Mahajan, Mitliagkas, Neal, Syrgkanis (2023)](https://arxiv.org/abs/2211.01939) is the **most comprehensive** study in terms of scope. The authors compare many metrics on 144 datasets and 415 estimators. They find that “*no metric significantly dominates the rest*” but “*metrics that use DR elements seem to always be among the candidate winners*”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c79cf7e-d9a7-4174-948c-cd3a7fd781ef",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc944d68-3b3d-44ff-be91-3e79e1bb69b6",
   "metadata": {},
   "source": [
    "In this article, we have explore multiple methods to evaluate uplift models. The **main challenge** is the unobservability of the variable of interest, the Individual Treatment Effects. Therefore, different methods try to evaluate uplift models either using other variables, using proxy outcomes, or approximating the effect of implied optimal policies.\n",
    "\n",
    "It is hard to recommend using a single method since there is **no consensus** on which one performs best, neither from a theoretical nor from an empirical perspective. Loss functions that use R-learner and DR-learner tend to perform **consistently better**, but are also biased towards the corresponding learners. Understanding how these metrics work however, can help understanding their biases and limitation, in order to take the most appropriate decisions depending on the specific scenario. \n",
    "\n",
    "It is also important to underline that metrics such as the uplift curve can be very useful in *understanding* and *explaining* estimators, but might not be best to *evaluate* or *compare* them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b19124c-5511-4862-913e-2084fda06c7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1227d84-b217-4120-850b-89a1004be77f",
   "metadata": {},
   "source": [
    "- Schuler, Baiocchi, Tibshirani, Shah (2018), [\"A comparison of methods for model selection when estimating individual treatment effects\"](https://arxiv.org/abs/1804.05146)\n",
    "\n",
    "- Curth, van der Schaar (2023), [\"In Search of Insights, Not Magic Bullets: Towards Demystification of the Model Selection Dilemma in Heterogeneous Treatment Effect Estimation\"](https://arxiv.org/abs/2302.02923)\n",
    "\n",
    "- Mahajan, Mitliagkas, Neal, Syrgkanis (2023), [\"Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation\"](https://arxiv.org/abs/2211.01939)\n",
    "\n",
    "- Gutierrez, Gerardy (2017), [\"Causal Inference and Uplift Modeling: A review of the literature\"](https://proceedings.mlr.press/v67/gutierrez17a/gutierrez17a.pdf)\n",
    "\n",
    "- Nie, Wager (2017), [\"Quasi-Oracle Estimation of Heterogeneous Treatment Effects\"](https://arxiv.org/abs/1712.04912)\n",
    "\n",
    "- Saito, Yasui (2020), [\"Counterfactual Cross-Validation: Stable Model Selection Procedure for Causal Inference Models\"](https://arxiv.org/abs/1909.05299)\n",
    "\n",
    "- Hitsch, Misra, Zhang (2023), [\"Heterogeneous Treatment Effects and Optimal Targeting Policy Evaluation\"](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3111957)\n",
    "\n",
    "- Kunzel, Sekhon, Bickel, Yu (2017), [\"Meta-learners for Estimating Heterogeneous Treatment Effects using Machine Learning\"](https://arxiv.org/abs/1706.03461)\n",
    "\n",
    "- Kennedy (2022), [\"Towards optimal doubly robust estimation of heterogeneous causal effects\"](https://arxiv.org/abs/2004.14497)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e208773-1860-4653-b1eb-26feaf6a6f86",
   "metadata": {},
   "source": [
    "### Related Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf2d42b-193c-40f0-899d-15678d3281a6",
   "metadata": {},
   "source": [
    "- [Understanding Meta Learners](https://towardsdatascience.com/8a9c1e340832)\n",
    "\n",
    "- [Understanding AIPW, the Doubly-Robust Estimator](https://towardsdatascience.com/ed4097dab27a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bd4b92-d4ef-4eeb-988d-e42257f8b6e3",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc472e-db7e-45b5-bca8-8b4e869eee21",
   "metadata": {},
   "source": [
    "You can find the original Jupyter Notebook here:\n",
    "\n",
    "https://github.com/matteocourthoud/Blog-Posts/blob/main/notebooks/evaluate_uplift.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
